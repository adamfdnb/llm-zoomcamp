{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7791fe9d-0c53-4c68-9947-722d5eadd061",
   "metadata": {},
   "source": [
    "#### LLM Zoomcamp 2.8 - Ollama + Elastic in Docker Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c889f552-e1a0-4416-91da-76d553848a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d75eb09-975b-4bdb-aafa-26e7f8312431",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134ba319-2b45-4f3a-aa09-25f783bca517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550.48s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "  Downloading elasticsearch-8.14.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting elastic-transport<9,>=8.13 (from elasticsearch)\n",
      "  Downloading elastic_transport-8.13.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.0.7)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.2.2)\n",
      "Downloading elasticsearch-8.14.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.2/480.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading elastic_transport-8.13.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.13.1 elasticsearch-8.14.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1efecd-a549-4c89-8a7d-3dc046322358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea97546-078d-47da-afa4-630cb3de1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843ab81e-3ad8-4fb2-930c-6e94b37c277c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '6201952bb194', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'h6_D5IUvRICrhJT5XUhDnA', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05573da8-3b98-4ff1-ac0a-4cd1f4932dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true}"
     ]
    }
   ],
   "source": [
    "!curl -X DELETE \"localhost:9200/course-questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0334ea22-26e8-48b3-92de-494e8263f762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6219fec8-19fc-4906-97f1-668afb1f2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b44ed5-05c0-40dc-9614-11c70e90c9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab04f40-3797-4016-a24d-9c5b57f251fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade notebook jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8de85-d1e1-4ab3-a49a-3d9ec42ba50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d096a0-3156-4da4-9577-aed702a55ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc293586-185f-4581-a69c-32324e16c4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda09e80467943a5983fc7ed15afa814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3fca3c0-0ed6-4780-b59c-6b0e9dd3cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = es_client.search(index=index_name, body=search_query\n",
    "        )\n",
    "        result_docs = []\n",
    "        for hit in response['hits']['hits']:\n",
    "            result_docs.append(hit['_source'])\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    \n",
    "    return result_docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92774be-9045-46d4-b00d-92846c2c8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='phi3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22fe9924-792a-4361-bec4-96077e5aaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_result = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_result)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8332ac8e-ad6c-4646-92ba-9aba94502cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" As a course teaching assistant, I can confirm that if you find the Data Engineering Bootcamp valuable and relevant to your interests or career goals, there are multiple ways for you to contribute:\\n\\nFirstly, star the GitHub repository associated with this bootcamp as well as share it on social media platforms where like-minded individuals gather. Your support will not only show appreciation but also help maintain a vibrant learning community around these courses and projects that can lead directly back to their creators for more opportunities or improvements in future iterations of the course materials.\\n\\nIf you spot any areas within this repository, whether it be textual clarity on explanations/descriptions or structural enhancements like organization into separate modules with clear navigation links between them, feel empowered to fork and create a Pull Request (PR). By doing so not only do you contribute back but also get involved in shaping the learning materials directly. It's collaborative efforts that keep knowledge-sharing platforms thriving!\\n\\nPlease note though as per our FAQ document, although participation is encouraged for registered members it isn’t mandatory to receive a certificate or course confirmation email since acceptance into this program doesn't require registration prior. You can start learning and submitting homeworks without registerment directly in the self-paced mode through Google Cloud Platform (GCP). The certification, as clarified by our team is only awarded when you successfully finish a 'live’ cohort of learners together where peer review process takes place which isn't available for self-study course.\\n\\nRegarding your other inquiries: You can join the GitHub repository to view and possibly contribute towards it, as this bootcamp appears largely based on open source materials (or at least that seems likely given its structure). However please remember while you are able to start learning about setting up dependencies via our FAQ document or by installing Google Cloud SDK. It would also be beneficial for beginners who may not yet have installed necessary tools such as Python, Terraform etc. \\n\\nTo learn more specifics on how this bootcamp works including accessing certain files within GCP like the ny-rides.json file and working with dbt in Git repositories visit our GitHub page where we maintain a detailed FAQ document covering all aspects of these resources along with step by step instructions for setting up dependencies, coding exercises etc., ensuring to guide every learner through their journey into Data Engineering efficiently.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'I just discovered the course. Can I still join it?'\n",
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e85f7b98-2259-4a46-89c2-311e854d3ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " As a course teaching assistant, I can confirm that if you find the Data Engineering Bootcamp valuable and relevant to your interests or career goals, there are multiple ways for you to contribute:\n",
      "\n",
      "Firstly, star the GitHub repository associated with this bootcamp as well as share it on social media platforms where like-minded individuals gather. Your support will not only show appreciation but also help maintain a vibrant learning community around these courses and projects that can lead directly back to their creators for more opportunities or improvements in future iterations of the course materials.\n",
      "\n",
      "If you spot any areas within this repository, whether it be textual clarity on explanations/descriptions or structural enhancements like organization into separate modules with clear navigation links between them, feel empowered to fork and create a Pull Request (PR). By doing so not only do you contribute back but also get involved in shaping the learning materials directly. It's collaborative efforts that keep knowledge-sharing platforms thriving!\n",
      "\n",
      "Please note though as per our FAQ document, although participation is encouraged for registered members it isn’t mandatory to receive a certificate or course confirmation email since acceptance into this program doesn't require registration prior. You can start learning and submitting homeworks without registerment directly in the self-paced mode through Google Cloud Platform (GCP). The certification, as clarified by our team is only awarded when you successfully finish a 'live’ cohort of learners together where peer review process takes place which isn't available for self-study course.\n",
      "\n",
      "Regarding your other inquiries: You can join the GitHub repository to view and possibly contribute towards it, as this bootcamp appears largely based on open source materials (or at least that seems likely given its structure). However please remember while you are able to start learning about setting up dependencies via our FAQ document or by installing Google Cloud SDK. It would also be beneficial for beginners who may not yet have installed necessary tools such as Python, Terraform etc. \n",
      "\n",
      "To learn more specifics on how this bootcamp works including accessing certain files within GCP like the ny-rides.json file and working with dbt in Git repositories visit our GitHub page where we maintain a detailed FAQ document covering all aspects of these resources along with step by step instructions for setting up dependencies, coding exercises etc., ensuring to guide every learner through their journey into Data Engineering efficiently.\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
